import json

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer


class PersianMeterClassifier:
    def __init__(
        self,
        model_path: str = "./persian-meter-classifier",
        label_map_path: str = "./label_map.json",
    ):
        print("Loading model and tokenizer...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)

        with open(label_map_path, "r", encoding="utf-8") as f:
            self.label_map = json.load(f)

        # Create reverse mapping (id -> label)
        self.id_to_label = {v: k for k, v in self.label_map.items()}

        print(f"Model loaded! Can classify {len(self.label_map)} different meters:")

        for meter, _ in list(self.label_map.items())[:5]:
            print(f"  - {meter}")
        if len(self.label_map) > 5:
            print(f"  ... and {len(self.label_map) - 5} more")
        print()

    def predict(
        self, hemistichs: list[str], top_k: int = 3
    ) -> list[list[tuple[str, float]]]:
        inputs = self.tokenizer(
            hemistichs, truncation=True, padding=True, return_tensors="pt"
        )

        with torch.no_grad():
            outputs = self.model(**inputs)
            probabilities = torch.softmax(outputs.logits, dim=-1)

        results = []
        for i, _ in enumerate(hemistichs):
            top_probs, top_indices = torch.topk(probabilities[i], top_k)

            predictions = []
            for prob, idx in zip(top_probs, top_indices):
                meter_name = self.id_to_label[idx.item()]
                confidence = prob.item()
                predictions.append((meter_name, confidence))

            results.append(predictions)

        return results

    def predict_single(self, hemistich: str, top_k: int = 3) -> list[tuple[str, float]]:
        return self.predict([hemistich], top_k)[0]


def main():
    classifier = PersianMeterClassifier()

    test_hemistichs = [
        "ุงฺฏุฑ ุขู ุชูุฑฺฉู ุดุฑุงุฒ ุจูโโ ุฏุณุชโ ุขุฑูุฏ ุฏูู ูุง ุฑุง",
        "ุจู ุฎุงู ูููุฏููุด ุจูุฎุดูู ุณูููุฑููุฏ ู ุจูุฎุงุฑุง ุฑุง",
        "ุจุฏู ุณุงู ููู ุจุงู ฺฉู ุฏุฑ ุฌููููุช ูุฎูุงู ุงูุช",
        "ฺฉูุงุฑู ุขุจู ุฑูฺฉูุงุจุงุฏ ู ฺฏููโฺฏูุดุชู ููุตูููุง ุฑุง",
        "ุงฺฏุฑ ุชูุฏุจุงุฏ ุจุฑุงุฏ ุฒ ฺฉูุฌ",
        "ุจุฎุงฺฉ ุงูฺฏูุฏ ูุงุฑุณุฏู ุชุฑูุฌ",
        "ุณุชูฺฉุงุฑู ุฎูุงููุด ุงุฑ ุฏุงุฏฺฏุฑ",
        "ููุฑููุฏ ุฏุงููุด ุงุฑ ุจโููุฑ",
        "ุจุดูู ุงู ู ฺูู ุดฺฉุงุช ูโฺฉูุฏ",
        "ุงุฒ ุฌุฏุงโูุง ุญฺฉุงุช ูโฺฉูุฏ",
        "ฺฉุฒ ูููุณุชุงู ุชุง ูุฑุง ุจูุจุฑุฏูโุงูุฏ",
        "ุฏุฑ ููุฑู ูุฑุฏ ู ุฒู ูุงูุฏูโุงูุฏ",
        "ุชุง ฺฉ ุจู ุชููุง ูุตุงู ุชู ฺฏุงูู",
        "ุงุดฺฉู ุดูุฏ ุงุฒ ูุฑ ูฺู ฺูู ุณู ุฑูุงูู",
        "ุฎูุงูุฏ ุจู ุณุฑ ุขุฏุ ุดุจ ูุฌุฑุงู ุชู ุง ููุ",
        "ุง ุชุฑ ุบูุช ุฑุง ุฏู ุนุดุงู ูุดุงูู",
    ]

    print("๐ Classifying hemistichs...\n")

    for hemistich in test_hemistichs:
        print(f"๐ Hemistich: {hemistich}")
        predictions = classifier.predict_single(hemistich, top_k=3)

        print("๐ Predictions:")
        for i, (meter, confidence) in enumerate(predictions, 1):
            print(f"  {i}. {meter:<30} ({confidence:.1%})")
        print("-" * 64)


if __name__ == "__main__":
    main()
